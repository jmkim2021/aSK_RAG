import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
try:
    from pinecone import Pinecone  # new SDK
except Exception:
    Pinecone = None  # optional, fall back to sampling
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv

def load_system_prompt(path):
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° (í”„ë¡œì íŠ¸ ë£¨íŠ¸ì™€ backend í´ë” ëª¨ë‘ ì‹œë„)
PROJECT_ROOT = os.path.dirname(os.path.dirname(__file__))
load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, ".env"))
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY_KIM")
PINECONE_INDEX = os.getenv("PINECONE_INDEX_KIM")
PINECONE_ENV = os.getenv("PINECONE_ENVIRONMENT")
PINECONE_NAMESPACE = ""

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
os.environ["PINECONE_API_KEY"] = PINECONE_API_KEY
os.environ["PINECONE_ENVIRONMENT"] = PINECONE_ENV

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    openai_api_key=OPENAI_API_KEY
)
vectorstore = PineconeVectorStore.from_existing_index(
    index_name=PINECONE_INDEX,
    embedding=embeddings,
    namespace=PINECONE_NAMESPACE,
)

# system_prompt.txt ì ˆëŒ€ê²½ë¡œ
DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
system_prompt_path = os.path.join(DATA_DIR, "system_prompt.txt")
system_prompt = load_system_prompt(system_prompt_path)
prompt_template = (
    "{system_prompt}\n\n"
    "Question: {question}\n"
    "Context (chunks/clauses):\n{context}\n\n"
    "Output language: {answer_lang}. Write the entire answer in this language only.\n"
    "Important context rule: Items are tagged as [CONTRACT] (selected agreement) and [LAW] (latest legislation).\n"
    "Treat all [LAW] items as up-to-date and authoritative legal references.\n"
    "If the question concerns law or when [LAW] appears in context, explicitly compare the contract clauses against the latest legislation: identify alignment, discrepancies, and whether any contract provision is overridden by mandatory law.\n"
    "Where the contract text cites outdated statutes, treat [LAW] as controlling for the legal requirement; still ground obligations and remedies primarily in [CONTRACT].\n"
    "Summarize the comparison outcome in the first paragraph. In the evidence list, pair citations from both sources where relevant.\n\n"
    "Citation style (STRICT): Use only the file name and pages inside parentheses, no tags.\n"
    "Format exactly as: (DocumentName, p.X[, p.Y ...]) â€” e.g., (contract3.pdf, p.7), (law1.pdf, p.18, p.28).\n"
    "Use the exact file name as DocumentName. Prefix each page with 'p.'. Place a single space after each comma.\n"
    "Do not include any tags or extra markers in citations (no [CONTRACT], [LAW], brackets, or dashes). Use only (DocumentName, p.â€¦).\n\n"
    "Respond in exactly three distinct paragraphs, in this order:\n"
    "- First, provide a concise summary answer.\n"
    "- Next, present all supporting clause/page/quotation evidence (one per line, as a list, direct from the context).\n"
    "- Finally, offer concrete practical advice or analysis for the user's position, based only on the quoted clauses.\n"
    "If the user's question contains the exact Korean word 'ë„ì‹í™”', then AFTER the above three paragraphs, append one additional section at the very end with the exact header line below (do NOT translate this header):\n"
    "ã€ë„ì‹í™” êµ¬ì¡° ì œì•ˆã€‘\n"
    "In that section, do NOT draw a full diagram. Instead, provide a detailed plan for how to visualize it: (1) Node list with labels and 1-line descriptions; (2) Edge list describing directions and conditions; (3) Recommended layout (top-down/left-right) and ordering; (4) Grouping/clusters and boundaries; (5) Legend/notations to use; and (6) Optional short ASCII sketch up to 6 lines.\n"
    "For the optional ASCII sketch: use ONLY plain ASCII characters '-', '>', '(', ')', '[', ']', ':' and spaces; format each line as either 'A -> B' or '- Node: short note'; do NOT attempt alignment, boxes, or grids; do NOT use code fences or Markdown; keep labels in {answer_lang}.\n"
    "\nTerminology policy (STRICT): For the following industry terms, do NOT translate the term itself.\n"
    "Always write the original term exactly as in the source (case preserved). On the first occurrence, immediately add a translation or clarifying note in parentheses in the user's requested output language ({answer_lang}); on later occurrences, the parentheses are optional. Never use any other language in parentheses.\n"
    "Terms: Operator; Non-Operator; Participating Interest; Joint Operating Agreement; Production Sharing Agreement; Cost Oil; Cost Gas; Profit Oil; Profit Gas; Exclusive Operation; Work Program and Budget; AFE; Carried Interest; Relinquishment; Surrender; Defaulting Party; Force Majeure; Assignment; Withdrawal; Entitlement; Lifting; Take or Pay; Make Up Gas; Joint Account; Gross Negligence/Willful Misconduct; Abandonment; Development Plan; Appraisal Well; Exploration Well; Royalty; Additional Profits Tax (APT); Joint Operating Committee (JOC).\n"
    "Example format (use these exact visual headers, not Markdown):\n"
    "ã€ë‹µë³€ ìš”ì•½ã€‘\n(Your summary here)\n\n"
    "ã€ê·¼ê±°ã€‘\n(Clause numbers/pages/quotes with citations)\n\n"
    "ã€ì‹¤ë¬´ì  ì¡°ì–¸ã€‘\n(Your advice here)\n"
    "Insert one blank line after each header.\n"
    "Do not add section numbers or extra labels ('1.', '2.', etc). Use only the three specified headers and line breaks to separate each part, EXCEPT when the question contains 'ë„ì‹í™”'â€”in that case, add the single extra section at the very end for the schematic structure proposal."
)
prompt = PromptTemplate.from_template(prompt_template)
llm = ChatOpenAI(model="gpt-4.1", openai_api_key=OPENAI_API_KEY, temperature=0)

# ë²•ë ¹ í‚¤ì›Œë“œ ê°ì§€
LAW_KEYWORDS = [
    "ë²•", "ë²•ë ¹", "law", "legislation"
]

def _contains_law_keyword(text: str) -> bool:
    if not text:
        return False
    lowered = text.lower()
    if any(k in text for k in ["ë²•", "ë²•ë ¹"]):
        return True
    return any(k in lowered for k in ["law", "legislation"]) 

def rag_search(query, file_name=None, category=None, answer_lang="ko", top_k=5):
    # 1) ê³„ì•½ì„œ ê²€ìƒ‰: ì„ íƒí•œ ê³„ì•½ì„œëŠ” í•­ìƒ í¬í•¨
    contract_docs: list = []
    if file_name:
        contract_docs = vectorstore.similarity_search(
            query, k=top_k, filter={"file_name": file_name}
        )
    else:
        # íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ìš°ì„  í•„í„° ì—†ì´ ì „ì²´ì—ì„œ ê²€ìƒ‰
        all_docs = vectorstore.similarity_search(
            query, k=top_k, filter=None
        )
        # ê³„ì•½ì„œ ì¶”ì • ê·œì¹™: category=='contract' ì´ê±°ë‚˜ íŒŒì¼ëª…ì´ contractë¡œ ì‹œì‘
        contract_docs = [
            d for d in all_docs
            if (d.metadata.get("category") == "contract")
            or str(d.metadata.get("file_name", "")).lower().startswith("contract")
        ]
        # ê³„ì•½ì„œë¡œ ì¶”ì •ë˜ëŠ” ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²°ê³¼ë¼ë„ ë°˜í™˜
        if not contract_docs:
            contract_docs = all_docs

    # 2) ë²•ë ¹ í‚¤ì›Œë“œê°€ ìˆê³  íŠ¹ì • ê³„ì•½ì„œê°€ ì„ íƒëœ ê²½ìš°ì—ë§Œ law ì¹´í…Œê³ ë¦¬ë¥¼ ë¹„êµìš©ìœ¼ë¡œ ì¶”ê°€
    add_law = bool(file_name) and (_contains_law_keyword(query) or (category == "law"))
    law_docs: list = []
    if add_law:
        law_docs = vectorstore.similarity_search(
            query, k=top_k, filter={"category": "law"}
        )

    # 3) ì»¨í…ìŠ¤íŠ¸ ë³‘í•©: ê³„ì•½ì„œ ìš°ì„ , ë‹¤ìŒ ë²•ë ¹
    docs = contract_docs + law_docs
    def _line_for(doc):
        src_cat = doc.metadata.get("category")
        src_file = doc.metadata.get("file_name")
        raw_page = doc.metadata.get("page_num")
        try:
            page_num = int(raw_page) if raw_page is not None else 0
        except Exception:
            page_num = 0
        src_tag = "CONTRACT" if (src_cat == "contract" or (file_name and src_file == file_name)) else ("LAW" if src_cat == "law" else (src_cat or "SRC"))
        return f"- [{src_tag}] [{src_file or 'ì•Œìˆ˜ì—†ìŒ'} p.{page_num}] {doc.page_content}"

    context = "\n".join([_line_for(doc) for doc in docs])
    prompt_txt = prompt.format(
        system_prompt=system_prompt,
        question=query,
        context=context,
        answer_lang=answer_lang,
    )

    # ğŸ”¥ ìš”ì²­ëœ ì–¸ì–´ë¡œ ì§ì ‘ ìƒì„± (ìš©ì–´/ê´„í˜¸ ì–¸ì–´ ì¼ê´€ì„± ë³´ì¥)
    answer = llm.invoke(prompt_txt).content.strip()

    # ì²­í¬ ë¯¸ë¦¬ë³´ê¸° ë¦¬ìŠ¤íŠ¸
    chunk_previews = []
    for i, chunk in enumerate(docs, 1):
        file_ = chunk.metadata.get("file_name", "ì•Œìˆ˜ì—†ìŒ")
        raw_page = chunk.metadata.get("page_num")
        try:
            page_ = int(raw_page) if raw_page is not None else 0
        except Exception:
            page_ = 0
        cat_ = chunk.metadata.get("category", "ë¯¸ì§€ì •")
        text = chunk.page_content.replace("\n", " ")
        preview = text[:180]
        src_tag = "CONTRACT" if (cat_ == "contract" or (file_name and file_ == file_name)) else ("LAW" if cat_ == "law" else (cat_ or "SRC"))
        chunk_previews.append(
            f"{i}. [{src_tag}] [{file_} / p.{page_}] {preview}{'...' if len(text) > 180 else ''}"
        )
    return {
        "question": query,
        "answer": answer,
        "file": file_name or "ì „ì²´ ê³„ì•½ì„œ",
        "category": ("law" if add_law else (category or "ì „ì²´")),
        "preview_chunks": chunk_previews,
    }


# ì‹ ë¢°ì„±(Confidence) ê´€ë ¨ ë¡œì§ì€ ì‚¬ìš©ë˜ì§€ ì•Šì•„ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.


def list_index_file_names(category: str | None = None, top_k: int = 1000) -> list[str]:
    """Pinecone ë²¡í„° ì¸ë±ìŠ¤ì—ì„œ ë©”íƒ€ë°ì´í„°ì˜ file_name ê°’ì„ ìˆ˜ì§‘í•´ ì •ë ¬ëœ ìœ ë‹ˆí¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•œë‹¤.

    ì „ëµ: ì¤‘ë¦½ ì¿¼ë¦¬ë¡œ ìƒìœ„ kê°œë¥¼ ì¡°íšŒí•´ file_nameì„ ìˆ˜ì§‘í•œë‹¤. ì¸ë±ìŠ¤ ê·œëª¨ê°€ ì‘ì„ ë•Œ ì‹¤ìš©ì ì´ë‹¤.
    í•„ìš” ì‹œ kë¥¼ ì¡°ì •í•´ ì»¤ë²„ë¦¬ì§€ë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.
    """
    filter_dict = {"category": category} if category else None
    try:
        docs = vectorstore.similarity_search(" ", k=top_k, filter=filter_dict)
    except Exception:
        # ì„ë² ë”©/ëª¨ë¸ ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []
    names = []
    seen = set()
    for doc in docs:
        name = (doc.metadata or {}).get("file_name")
        if name and name not in seen:
            seen.add(name)
            names.append(name)
    names.sort(key=lambda x: x.lower())
    return names


def list_all_file_names(category: str | None = None) -> list[str]:
    """Pineconeì˜ list APIë¥¼ ì´ìš©í•´ ëª¨ë“  ë²¡í„°ë¥¼ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìˆœíšŒí•˜ë©° file_nameì„ ìˆ˜ì§‘í•œë‹¤.
    ê°€ëŠ¥í•œ ê²½ìš° ì´ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ê³ , ì‹¤íŒ¨ ì‹œ list_index_file_namesë¡œ í´ë°±í•œë‹¤.
    """
    if Pinecone is None or not PINECONE_API_KEY or not PINECONE_INDEX:
        return list_index_file_names(category=category, top_k=2000)

    try:
        pc = Pinecone(api_key=PINECONE_API_KEY)
        index = pc.Index(PINECONE_INDEX)
        file_names: set[str] = set()
        token = None
        while True:
            # ë‹¤ì–‘í•œ SDK ë²„ì „ì„ í˜¸í™˜í•˜ê¸° ìœ„í•´ kwargsë¥¼ ìœ ì—°í•˜ê²Œ ì „ë‹¬
            kwargs = {"limit": 1000, "include_values": False, "include_metadata": True}
            if PINECONE_NAMESPACE:
                kwargs["namespace"] = PINECONE_NAMESPACE
            if token:
                kwargs["pagination_token"] = token
            resp = index.list(**kwargs)

            # respê°€ dict ë˜ëŠ” ê°ì²´ì¼ ìˆ˜ ìˆìŒ
            vectors = None
            if isinstance(resp, dict):
                vectors = resp.get("vectors") or resp.get("data")
                token = (resp.get("pagination") or {}).get("next") or resp.get("pagination_token")
            else:
                vectors = getattr(resp, "vectors", None) or getattr(resp, "data", None) or resp
                token = getattr(resp, "pagination_token", None) or getattr(resp, "next", None)

            if not vectors:
                break
            for v in vectors:
                md = getattr(v, "metadata", None)
                if md is None and isinstance(v, dict):
                    md = v.get("metadata")
                name = (md or {}).get("file_name")
                if name:
                    file_names.add(name)
            if not token:
                break
        names = sorted(file_names, key=lambda x: x.lower())
        # í•„í„° ìš”ì²­ ì‹œ ì ìš©
        if category:
            # list API í˜¸ì¶œì—ì„œ ë©”íƒ€ í•„í„°ë¥¼ ëª» ê±¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ í›„ì²˜ë¦¬(ì¶”ì •)
            names = [n for n in names if n]
        return names
    except Exception:
        # ì–´ë–¤ ì´ìœ ë¡œë“  ì‹¤íŒ¨í•˜ë©´ ìƒ˜í”Œë§ í´ë°±
        return list_index_file_names(category=category, top_k=5000)
